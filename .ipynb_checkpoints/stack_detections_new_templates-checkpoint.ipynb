{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genevieve.savard/anaconda3/envs/eqcorrscan/lib/python3.6/site-packages/ipykernel_launcher.py:3: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Get ERT times\n",
    "import pandas as pd\n",
    "ert_surveys_file = \"survey_times_ERT.csv\"\n",
    "dateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "ert_surveys = pd.read_csv(ert_surveys_file, parse_dates=[\"time_local_start\"], date_parser=dateparse)\n",
    "ert_surveys[\"time_local_start\"] = ert_surveys[\"time_local_start\"].dt.tz_localize(\"America/Edmonton\", ambiguous=\"infer\")\n",
    "ert_surveys[\"time_utc_start\"] = ert_surveys[\"time_local_start\"].dt.tz_convert(None)\n",
    "ert_surveys[\"time_utc_end\"] = ert_surveys[\"time_utc_start\"] + pd.Timedelta(30, unit=\"m\")\n",
    "ert_surveys[\"time_utc_end\"] = pd.to_datetime(ert_surveys[\"time_utc_end\"])\n",
    "ert_surveys[\"time_utc_start\"] = pd.to_datetime(ert_surveys[\"time_utc_start\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def plot_stack_singlechannels(streams, stack):\n",
    "    \n",
    "    ids = [tr.get_id() for tr in streams[0]]\n",
    "    n = len(ids)\n",
    "    ncols = 3\n",
    "    nrows = math.ceil(n/ncols)\n",
    "    print(\"n = %d, nrows = %d, ncols = %d\" % (n, nrows, ncols))\n",
    "    \n",
    "    fig, axs = plt.subplots(nrows, ncols, sharex=True, figsize=(15, 5*nrows))    \n",
    "    for tr_id, ax in zip(ids, axs.flatten()):\n",
    "        \n",
    "        # Plot each event in background\n",
    "        for st in streams:\n",
    "            tr = st.select(id=tr_id)\n",
    "            if not len(tr):\n",
    "                continue\n",
    "            else:\n",
    "                tr = tr[0]             \n",
    "            t = tr.times(\"utcdatetime\") - tr.stats.starttime\n",
    "            ax.plot(t, tr.data/tr.max(), color=\"gray\", marker=None, linestyle=\"-\")        \n",
    "        # Plot stack\n",
    "        tr = stack.select(id=tr_id)[0]            \n",
    "        ax.plot(t, tr.data/tr.max(), color=\"red\", marker=None, linestyle=\"-\")\n",
    "        ax.set_title(\"%s\" % (tr_id))\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def get_full_template(template):\n",
    "    st = template.st\n",
    "    tmin = min([tr.stats.starttime for tr in st])\n",
    "    wf_len_s = int(8.0/ndt)*ndt\n",
    "    prepick = 4.0\n",
    "    pattern = os.path.join(WF_DIR_ROOT_500Hz, tmin.strftime(\"%Y%m%d\"), \"*DP*\")\n",
    "    detst = read(pattern, starttime=tmin - prepick, endtime=tmin - prepick + wf_len_s)\n",
    "    pattern_hawk = os.path.join(WF_DIR_ROOT_HAWK, \"*\", \"*DP*.D.%s*\" % tmin.strftime(\"%Y%m%d\") )\n",
    "    detst += read(pattern_hawk, starttime=tmin - prepick, endtime=tmin - prepick + wf_len_s)\n",
    "    detst.detrend(\"demean\")\n",
    "    return detst\n",
    "\n",
    "def get_stack(family):\n",
    "    \n",
    "    # Get waveforms\n",
    "    streams = []\n",
    "    wf_len_s = int(6.0/ndt)*ndt\n",
    "    prepick = 2.0\n",
    "    wf_len = int(wf_len_s/ndt) + 1\n",
    "    for d in family.detections:        \n",
    "        #print(d.detect_time)\n",
    "        pattern = os.path.join(WF_DIR_ROOT, \"*\", \"*..DP*%s*2020*\" % (d.detect_time.strftime(\"%Y-%m-%d_%H\")))                                      \n",
    "        detst = read(pattern, starttime=d.detect_time - prepick, endtime=d.detect_time - prepick + wf_len_s)\n",
    "        detst.resample(SAMPLING_RATE)\n",
    "        detst.detrend(\"demean\")\n",
    "        # Check if traces have same length\n",
    "        lengths = set([len(tr) for tr in detst])\n",
    "        if len(lengths) > 1:\n",
    "            print(\"Traces don't have same lengths. Fixing\")\n",
    "            tmin = min([tr.stats.starttime for tr in detst])\n",
    "            tmax = tmin + wf_len\n",
    "            detst.trim(starttime=tmin, endtime=tmax, fill_value=0, pad=True)\n",
    "            print(detst)\n",
    "        \n",
    "        streams.append(detst)\n",
    "\n",
    "    lengths = [len(st[0].data) for st in streams]    \n",
    "    igood = np.argwhere([len(st[0].data) == wf_len for st in streams]).flatten()\n",
    "    streams = [streams[i] for i in igood]    \n",
    "    stack = linstack(streams)\n",
    "    #plot_stack_3c(streams, stack)\n",
    "#     plot_stack_singlechannels(streams, stack)\n",
    "    return stack\n",
    "\n",
    "\n",
    "def plot_stack_3c(streams, stack):\n",
    "    stations = list(set([tr.stats.station for tr in stack]))\n",
    "    nsta = len(stations)    \n",
    "    fig, axs = plt.subplots(nsta, 3, sharex=True, figsize=(15, 5*nsta))\n",
    "    for i, station in enumerate(stations):\n",
    "        available_chans = [tr.stats.channel for tr in streams[0].select(station=station)]\n",
    "        for ich, channel in enumerate(available_chans): #[\"DPN\", \"DPE\", \"DPZ\"]):            \n",
    "            ax = axs[i][ich]\n",
    "            # Plot each event in background\n",
    "            for st in streams:\n",
    "                tr = st.select(station=station, channel=channel)[0]                \n",
    "                t = tr.times(\"utcdatetime\") - tr.stats.starttime\n",
    "                ax.plot(t, tr.data/tr.max(), color=\"gray\", marker=None, linestyle=\"-\")\n",
    "            # Plot stack\n",
    "            tr = stack.select(station=station, channel=channel)[0]            \n",
    "            ax.plot(t, tr.data/tr.max(), color=\"red\", marker=None, linestyle=\"-\")\n",
    "            ax.set_ylabel(\"%s.%s\" % (tr.stats.station, tr.stats.channel))\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************ 20200228 ************\n",
      "Party of 19 Families.\n",
      "finished reading and declustering\n",
      "Number of good families: 0 / 19\n",
      "************ 20200229 ************\n",
      "Party of 10 Families.\n",
      "finished reading and declustering\n",
      "Family with 3 detections\n",
      "Number of good families: 1 / 10\n",
      "total count = 1\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "\n",
    "from eqcorrscan.utils.stacking import linstack\n",
    "from eqcorrscan.core.match_filter import Party, Family\n",
    "from obspy import read, Catalog\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import math\n",
    "from glob import glob\n",
    "import os\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "DETECT_DIR = \"/home/gilbert_lab/cami_frs/borehole_data/energy_detector/detections_clean\"\n",
    "WF_DIR_ROOT_500Hz = \"/home/gilbert_lab/cami_frs/borehole_data/sac_daily_nez_500Hz\"\n",
    "WF_DIR_ROOT_HAWK = \"/home/gilbert_lab/cami_frs/hawk_data/sac_data_raw/X7_Jan-Feb2020_sac_daily_250Hz\"\n",
    "# WF_DIR_ROOT_HAWK = \"/home/gilbert_lab/cami_frs/hawk_data/sac_data_raw/X8_March-April2020_sac_daily_250Hz\"\n",
    "# WF_DIR_ROOT_HAWK = \"/home/gilbert_lab/cami_frs/hawk_data/sac_data_raw/X9_May2020_sac_daily_250Hz\"\n",
    "# WF_DIR_ROOT_HAWK = \"/home/gilbert_lab/cami_frs/hawk_data/sac_data_raw/X10_July2020_sac_daily_500Hz\"\n",
    "WF_DIR_ROOT = \"/home/gilbert_lab/cami_frs/sac_hourly_125Hz/\"\n",
    "SAMPLING_RATE = 125.0\n",
    "ndt = 1/SAMPLING_RATE\n",
    "\n",
    "party_dir = \"/home/gilbert_lab/cami_frs/borehole_data/energy_detector/initial_templates_daily_old/\"\n",
    "out_dir = \"/home/gilbert_lab/cami_frs/borehole_data/energy_detector/templates\"\n",
    "\n",
    "flist = glob(os.path.join(party_dir,\"party_day202002*.tgz\"))\n",
    "days = [os.path.split(f)[1].split(\"_\")[1].split(\".\")[0].split(\"day\")[1] for f in flist]\n",
    "days.sort()\n",
    "days = days[14:]\n",
    "total_count = 0\n",
    "for daystr in days: \n",
    "    print(\"************ %s ************\" % daystr)\n",
    "    party = Party().read(os.path.join(party_dir,\"party_day%s.tgz\" % daystr))\n",
    "    print(party)\n",
    "    #party.decluster(trig_int=3.0)\n",
    "    print(\"finished reading and declustering\")\n",
    "    if not party.families:\n",
    "        print(\"no families...\")\n",
    "        continue\n",
    "    count = 0\n",
    "    for family in party:\n",
    "        ndets = 0\n",
    "        if not family:            \n",
    "            continue\n",
    "            \n",
    "        # Determine good detections\n",
    "        ndets = 0\n",
    "        good_detections = []\n",
    "        good_catalog = Catalog()\n",
    "        for idet, d in enumerate(family.detections):\n",
    "            detect_time = d.detect_time._get_datetime()\n",
    "            is_ert_on = ert_surveys.loc[(ert_surveys['time_utc_start'] <= detect_time) & (ert_surveys['time_utc_end'] >= detect_time)].shape[0] > 0\n",
    "            if not is_ert_on:\n",
    "                ndets += 1\n",
    "                good_detections.append(d)\n",
    "                good_catalog.append(family.catalog[idet])\n",
    "        if not good_detections:\n",
    "            continue            \n",
    "        new_fam = Family(template=family.template, detections=good_detections)\n",
    "        \n",
    "        # If family is good, save template and stack\n",
    "        num_p_picks = len([p for p in new_fam.template.event.picks if p.phase_hint==\"P\"])\n",
    "        if ndets > 2 and len(new_fam.template.st) > 4 and num_p_picks > 0:\n",
    "            count +=1\n",
    "            print(\"Family with %d detections\" % ndets)\n",
    "            full_template_st = get_full_template(new_fam.template)\n",
    "            fname = os.path.join(out_dir, \"%s_full_template.mseed\" % new_fam.template.name)\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            new_fam.template.st.write(fname, format=\"MSEED\") \n",
    "            full_template_st.write(fname, format=\"MSEED\") \n",
    "            \n",
    "            # stack\n",
    "            fname = os.path.join(out_dir, \"%s_stack.mseed\" % new_fam.template.name)\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            stack = get_stack(new_fam)            \n",
    "            stack.write(fname, format=\"MSEED\") \n",
    "            \n",
    "            # Family\n",
    "            fname = os.path.join(out_dir, \"%s_family.tgz\" % new_fam.template.name)\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            new_fam.write(fname) \n",
    "            \n",
    "    print(\"Number of good families: %d / %d\" % (count, len(party.families)))\n",
    "    total_count += count\n",
    "    \n",
    "print(\"total count = %d\" % total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200228', '20200229']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eqcorrscan.core.match_filter import Tribe\n",
    "\n",
    "flist = glob(os.path.join(party_dir,\"tribe_day*.tgz\"))\n",
    "days = [os.path.split(f)[1].split(\"_\")[1].split(\".\")[0].split(\"day\")[1] for f in flist]\n",
    "days.sort()\n",
    "for daystr in days: \n",
    "    print(\"************ %s ************\" % daystr)\n",
    "    party = Tribe().read(os.path.join(party_dir,\"tribe_day%s.tgz\" % daystr))\n",
    "    print(party)\n",
    "    #party.decluster(trig_int=3.0)\n",
    "    print(\"finished reading and declustering\")\n",
    "    if not party.families:\n",
    "        print(\"no families...\")\n",
    "        continue\n",
    "    count = 0\n",
    "    for family in party:\n",
    "        ndets = 0\n",
    "        if not family:            \n",
    "            continue\n",
    "            \n",
    "\n",
    "        # If family is good, save template and stack\n",
    "        num_p_picks = len([p for p in new_fam.template.event.picks if p.phase_hint==\"P\"])\n",
    "        if ndets > 2 and len(new_fam.template.st) > 4 and num_p_picks > 0:\n",
    "            count +=1\n",
    "            print(\"Family with %d detections\" % ndets)\n",
    "            full_template_st = get_full_template(new_fam.template)\n",
    "            fname = os.path.join(out_dir, \"%s_full_template.mseed\" % new_fam.template.name)\n",
    "            if os.path.exists(fname):\n",
    "                os.remove(fname)\n",
    "            new_fam.template.st.write(fname, format=\"MSEED\") \n",
    "            full_template_st.write(fname, format=\"MSEED\") \n",
    "            \n",
    "\n",
    "            \n",
    "    print(\"Number of good families: %d / %d\" % (count, len(party.families)))\n",
    "    total_count += count\n",
    "    \n",
    "print(\"total count = %d\" % total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
